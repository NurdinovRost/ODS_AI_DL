{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bc5f1a0adac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for fc1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1_B\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for fc1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1_B\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) \n",
    "\n",
    "#0.1, так как количество классов = 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302446, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301769, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302113, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301477, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302177, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302148, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301415, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302803, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301005, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302052, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302110, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302246, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302364, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303201, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302023, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302463, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302703, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302282, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302915, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x114e72be0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9jUlEQVR4nO29e5Akx33f+fn1+9093T2704sFCICGHpBEk/QSlCiREmmJAnQOQLJJGxQVJiWHaVnm3fkuJBsRsmkHdBdhiWGHw3f0HWEd42yfKZKmJRnnAIPkybyTIyxKWFIgyCUEcgGC2MXOzE73TL/f3Xl/VFZPz+w8eqarql/5idiYflRV5nZWffOXv8zfL0UphcFgMBiWF9+sK2AwGAwGdzFCbzAYDEuOEXqDwWBYcozQGwwGw5JjhN5gMBiWnMCsK3CYfD6v7r333llXw2AwGBaKr3zlK0Wl1PpR382d0N97771cvXp11tUwGAyGhUJEvnvcd8Z1YzAYDEuOEXqDwWBYcozQGwwGw5JjhN5gMBiWHCP0BoPBsOQYoTcYDIYlxwi9wWAwLDlzt45+pnzjd+H+n4BYdjblP/dJ2P3O+c/3+eGN74fM3c7V6Sx8/bOw8+Jsyl4WfuDn4OKDsyn7+h/Aq1+eTdkGi9QluPKLjl/WCL1NowSf/UV49/8Eb/tvvS+/U4ff/9v6jZzzIgqGfXjXP3CqVpMzHMLv/S2r/HPXf9VRsPcd+Cu/PZvin/k12H0J034z5PIVI/Su0rht/a3fnlH5O9bfx/4lvOn957vGRx/Yv47XtMuWyD/8T+CH//aphxuO4Ld/anbtB1bZb/1leOQ3Z1cHgysYH71No2j9bZZmU75dbix3/mvEcvv/D6+xy52m/qtOLGeNLGdBvwOdqmm/JcUIvU1TC9WshTKeP/814vkZdlRG6Kcmntv/Hb3GCUPDMLcYobexb/RFt+hnXf9pOqpVJ6Y76lns42zab6kxQm9jD5lnZlE5ZNHPekQSM0JxbuJ5GHShU/O+bNN+S40RepuR62ZGFnGjCP4QhBLnv0YsB609GA6cq9ekGNfN9Ni/3SyMDeO6WWqM0NvYFk23Zk1MeU2zZFlTMsXStlgeUNDcdaxaE9MoWZ1UMOJ92cuCbU3PwthwYo7IMLcYobcZ923Pws/dLFmTcdNgnz+r+htrcDpm3X4IRNe8L9vgOkbobZolEL/1ehZ+7kZxev+off5Mhv5FYw1Oy6zbL5a1oqsNS4cReptGEbL3W69n9qBNaRHb58+sozIW/VSY9jO4hBF6sJazNUuw/r3W+5n4SEvTW8TxWVqEJbNiY1pCcQhETPsZHMcIPVgRgcMerH+f9d5rH2m/Y00CT+26sX28Hk/G2h3ltHMMq46IXks/g8l0035LjRF62B8q514P4vPeohoFq0z5oPmDEEl7P/TvNqDfNhahE8RnlMbCiTkiw9xihB7GhHYdolnvHzQn88TEZhBGb9bQO8cs2m84hNauab8lZiKhF5GHReRFEbkuIk8c8f3/KCLfFJHnReQPROR1Y999QES+rf99wMnKO8a40MbzMxRKByyq2AyiYxsmfN4xZtF+rT1QQ9N+S8ypQi8ifuBjwCPAg8D7ROTwzgh/ClxRSr0B+CzwW/rcLPCPgLcCDwH/SETmb6HueJ6PWfhI7fKceNDis6i/HVVphGJqTPsZXGASi/4h4LpS6mWlVBf4FPDY+AFKqS8ppZr67ZeBy/r1TwNfVErtKqX2gC8CDztTdQcZt6hn4SN1Ms/ILF03ZjJvemI576OzTfstPZMI/V3AjbH3N/Vnx/E3gM+d5VwR+ZCIXBWRqzs7M9h4oVGEQBRCsRkKpUA0M/217Jz0XmZANLnonWMWa+lN+y09jk7GisgvAFeAj57lPKXUU0qpK0qpK+vr605WaTKaY2vYbdeNl4nBGg5GJcbz1lLRTnX6a01Kswi+IIRT3pW5rMwiFsLJOSLDXDKJ0L8GjO82fVl/dgAR+Ung14FHlVKds5w7c8bztMR1YrBW2ePyHXrIRmH0HsYC2B3lNAnZDBazaj8wk7FLzCRC/yzwgIjcJyIh4HHg6fEDRORNwMexRH5809XPA+8WkTU9Cftu/dl80RjL0zKLVLFNB6JibezreBnd2zBRlY4xq/YLJSEQ9q5Mg6ecKvRKqT7wYSyBfgH4jFLqmog8KSKP6sM+CiSAfy8iz4nI0/rcXeA3sDqLZ4En9WfzxXiemVn5SGNZZ65lX8frob9T9V91ZmJomPZbdgKTHKSUegZ45tBnHxl7/ZMnnPsJ4BPnraAnjFuks/KRxt7mzLVGOc097qjuerN35S0zkYyVRdXr9jNum6XGRMb2WtBr7C8t89pHOhxYAStOu2489fHuGteNU/h8lnXttY/etN9SY4T+8BZq9hDWKx9pq2xFJTr1oAVj3mZA7HehUzEWoZN4vcTXyTkiw1xihP5wsFIgbC0T9OpBczpPjJ0B0auOatRRGh+vY3jZfko5O0dkmEsm8tEvNaOowDyffvZV3vl9F7gQ8zA6dixz5b/9o1f4bql58vEn4PcJP//We3hd3EOLcCx8/jPP3uBb2zVvyl1SHnvjXfxQPAe3X/CmwG4DBh2I5fnCtS3+5Dvzt1ZilbiUifJLP3af49c1Qq/zihRVkr//H77Or/309/J34nnvfKS6Q6n5MvzD/3iNkN9H0H++9eiN7gAR4YmYh/XXHUo/muOJ/+t5Ar7z13/VafYG3Kq0+Jdp79uPeJ4n/9M32aq0CQfMQH9WvOFyxgi9K2ihvdWNAbBZaVlulKpHcV36QdsexAH4Z3/tz/OX3nDpXJd6+2/9Z7bs+peuO1bFE9G/X0klGaoqTz72Azz+0D3elL1kvP+3v8xmpQ2F3H50ttt7uGoX0TCaY6vS5m++437+/sPf526ZBs8xXXezCOLntVYIgK1K21sfqS7npu5oCunIuS9VSEUtofByRKLL2epZ9d+Yov6rzkYqat1/o+jsPfcL1YZGWZL0h2qq+88wvxih15sib1a7AFootY/bi8RgTSsqcbNulbWRjp77UhvpCFvVts6AWIde26laHk+zBAg3Ola9C1PUf9UppCPcrnUYROyVXx7Ms+iO+vYgCcBGygj9MmKEXi8t26y0AC30sTwMupZYul5+EeI5NsstfAIXkucPQy9kImxW2igvYwEaRYiusVnpjepgOB+FTITBUFH2pa0PvGo/4EbHch1eypiOehkxQq8Tmm1WLOt3t9GlF9Z7o3hhUem9OjcrbdaTYYL+8zdJIRWh2x9S9+sskl6svGkWdUfZJh7ykwybaZ/zYrtNbvct0fWs/fwhXmtY951xvS0nRui162arsu/m2MMWSg8sKp1nZ6vansptA/tun52hNQz3pqMq6fq32EhHEJPB8txspKz2u9XTQu9h+23WOoT8PrKxkPtlGjzHCP2YRWq7Tba9FMrm7qj8S1NaU5e022Srl9DX9qKj2h8RmWH/dNjt92rbmtj2rv3ybFXabKQj+Hymo15GVlvoB31olRlGc2xX27z5HstlYy+1dP1B01GJKmb56KcdNtvn3+h4KRS6oyy3zUTelKSjQSJBH69V+xBOe9h+Oav9jNtmaVltoW/tAYqGP01/qHjjPRkAXm1ry9RtH2m3DoMOnfAaje5g6qVt+XiYgE/4bjPoTQbE4RCauwyjOW7X2mZp3pSICIV0lM1q20pJ4OUcUbVl2m+JWW2h10K+q33yr19PkIoEuFH3gT/s/oOmr1/W5U/ro/f5hIupCFvVrs6A6HL922VQA2r+NEM1ff0N1vLG0Vp6TyZjS6hYlu1Kx1j0S8xqC33Djkq1fNqFdIRLmSib1Y43QUc6/YI9eTqtjx4sP++tSksHfbksFPr3sTtKs7RyegqZiHdBe/0udKo0g2t0B0MumY56aVltoddCdatrrXIopCNspCP7aRBcF3pLiDf1KgsnLKqN9Fh0ZdPlBFW6I7nd3+8oDdNR0EFvQ0/uP+v6+yNK037LyooLvSVUr7aj1tKyeMh60Co6utQj183NTgwRuJCc/kErpO2gKQ9cN/r69nLAQspYhNOykY4yGCpagYz70dm6/ewRpemol5fVFno9NH65GRmtAd9IRSnWuwyiHqT61dd/pRklnwgTciBr4EYqQqc/pBPyYDLPjqpsR4kG/aSiJlhqWgp65VLZl7Kiszsupn22XZd950aUhvlktYW+WYRImteqvZE1Y/uZG4GM+z7SZgn8Ib5TE0f887C/FrvqS1mrioYDR657JHro/1IjSiFjgqWcwL7/SnYsh5vGhm6/V9sxgn4hHz9/+g3DfLPiQl8apR8YCb3+W5E0dGvQ77hXvt6UfKvq3IoHe+WLFd3rcgbEZglCCW7Upl8aarCwk8Jt9e2gNxfnWbTQv9KKcjFlgqWWmYmEXkQeFpEXReS6iDxxxPfvEJGvikhfRN5z6LvfFJFv6H9/zamKO4IOVtoeSz9gC1ZJeRBdqoNVtiptx7I+jvKl6JVErrpvxtJHbBj/vCOsxYKEAj5es4P23G4/hJfqQdNRLzmnCr2I+IGPAY8ADwLvE5EHDx32KvBB4JOHzv1vgDcDbwTeCvyqiKSmrrVTNEt0w1l6AzVyediCv+2RUPYjWWqdvmMWfT5hBU3ZK3ncHfrrjrLWMULhEFbQVITvtuzoZnfbj+gam7WeiYFYciax6B8CriulXlZKdYFPAY+NH6CUekUp9TwwPHTug8AfKqX6SqkG8DzwsAP1doZGkYbfSglrh+8nwgGSkQA3O148aCVrdQXOrXjw66Cp77Y9sAibJTrhLIOhMmvoHaSQjnC9rv3lLrefcijPkmG+mUTo7wJujL2/qT+bhK8BD4tITETywDuBuw8fJCIfEpGrInJ1Z2dnwktPiVLQLI1yf4+7Tg5aVO76SKu+zB3lT8tGOsJ3mpFRGa7RKI06SmPRO0chHeU7VSAQcb39+pEs3f7QrLhZclydjFVKfQF4BvivwO8AfwTcsQxEKfWUUuqKUurK+vq6m1Xap1OFYY/S0HLRjN/oG+koLzVdtqj6HehU96NKHXzQNtIRrtd0ulm3hEIpaBatSWswPnoH2UhH2K51UG4HTTWLNANWIj/TUS83kwj9axy0wi/rzyZCKfU/K6XeqJT6KUCAb52tii4xWkOcJOT3kYvv5+G+lI7w7WoQxOee60Y/wDt6U/ALKeeWthVSEV6t9lHhlHsdVbcB/TYlZYJtnKaQjtAfKvoRl2MhGkVqPmfyLBnmm0mE/lngARG5T0RCwOPA05NcXET8IpLTr98AvAH4wnkr6yjN/U25L6bDB5aWbaQj7DR6qKiLD5qdfqEXJ58IEw74Hbt0IROl3RsydDPoS9d/ux8nEvSRiQXdKWcFsd147eCae+03HEJrd7TJjvHRLzenCr1Sqg98GPg88ALwGaXUNRF5UkQeBRCRt4jITeC9wMdF5Jo+PQj8FxH5JvAU8Av6erNnbA3x4dD9QjqCUlgWlVtD54adfiHmuDVsX68TdrH+WoBuduMU0lETLOUgdvvV/C7mpG+XQQ25PUgQ8Am5hAmWWmYmillXSj2D5Wsf/+wjY6+fxXLpHD6vjbXyZv7QQvtyI8zG6w4KrT2MbQUzBF0TSjv9QpSNC84KvT3f0PSniTVcmtzWUcPfbUXNhiMOY7dfmSSX3IrObuwn1LuYiuA3wVJLzepGxmqL9MVa+I6lgfYwtu7PuOe60df9dj3k+LDZTjdb9qVddN1Y132pETFLKx0mFw8R8vusZGNuRWc33RtRGuaP1RX6RhEViFIZhEaJpGxsi2qPlKs+boVwox1xfCJsPRnG7xN2VdLqUNzIgKhHJN+qh41QOIyIWOmy7b1/3TA2RiPKiFlauQKsrtA3d+lFssCdKw6SkSCJcIDiMOFeYrBmkWFkjSE+x4XS7xMuJMNs9xMw7LmTAbFRRPmClIfOd1QGy9hwde9f3XmYjno1WGGhL9IOZoCjlwZupCNs9RKghtAqO19+o2ilEsad9LAb6cjYJuduWIRW+gaQO0ZEhukppCO80rKD3txpP7BWTZmOevlZXaFvFKnZUbFH+JgL6Qg3XBXKEo2AVb4bW7hdSkd5xd7k3I0JvUaJlt1RGh+94xTSUV6q69/VpfYbBON0cH6OyDB/rK7QN4vsSYqA7+g83IXxNAIu+UgrOr+bk8FSNhvpCC813LQIS9ZkNc6mbzBYFNIRtuzEei61XzdkRcUaH/3ys8JCv0txmDw2D/dGOsp3RkNnd3ykJZUiFw8RCToXLGVTSEdGW/y5Uv9mkTIpQgEfayZYynE20hEqxFHic639GqOEeqajXnZWU+h7bejW2erFj52IKqQjlIY6o7LTFpWOStweJFyzpjbSEXaVrr8bI5JGiZ1hkkLa7CzlBoV0BIWPXijjUvtZeYr8PmE9aYKllp3VFHot3Dc6MQqZo62ZQjrCHno7N6d9pDoq8bVuzDVrqpCO0iTMwB92vqMa9KBTYatv1mC7hX1fNO1Nwp2muUtJJbmol+IalpvVFHptIX2nFT3Boo/SJUgvkHD+QdPlf/eE8qfFuq5Y+VKc7qi0K+FGJ26G/S6Ri4cI+sVKY+10++nMo7ddHFEa5ovVFPpRQq7EseH79gPQCmSc95GO5Ylx60FbT4bxCdTdyJcy1lEZoXAHn95AZpeE8+2nM4++1jUd9aqw0kK/R3K0heBhUpEA8ZCfqj/tvI9UX29XJV2z6IN+H+vJMGU3onv19W4P3Ku/wRqV3R4kXWu/77ZNR70qrKbQa6EtqdSxwSJ2GPqucuNBszoaS+jds6gK6ShFOw2Ck9j1x936rzqFdJRb3bi1y5mT0dljKaZNR70arKbQN4sMxU+VkycTC+kot4dJF3zc2qIn5eqDVkhH2Oq7MPRvjHdURijcojBKg6CsVBxOMWq/lOmoV4QVFfoSrUAav89P/oQ83BvpCFvduCWUTiYGa5To+uN0Cbo6dN5IR3itE4Nu3VpS6hTNIgphj6QZ+rvIRjrCzihoysHOWhsaJVKm/VaE1RT6RpGqL31qHu5L6Qg3ulEYdCyxdIpmkZo/TdalYCmbS+kom30XgqYaRVqBFAF/4MAWjAZnKaSjlEZLfB10v43NER03R2VYLlZT6JsldtXp1uhGOkrJjaCjZokKKdc37DgQNOXkPEOzRM1nWYMmWMo9Ci6230ACNCXKutlZaiVYTaFvFNkZni70hXRkX+gdtoh3PPBvW/V3wSJslthVZtjvNgfuP0fbr0jdn+FCMkrAv5oSsGqsZCurZslaQ3yKRb2RjrBnC6WjPtISWz331tDbbIxH9zZ3nbuw7ijNRKy75BJh6j432q9EWUxHvUqsntAPB9DaozhMHJv+wOaSGz5SpVCNIpv9BJdOKX9arIAb54f+qlnklgm2cR2/T1hLJWn54g67booUh8Y/v0qsntA3dxEUpQlcJ6logGZgTZ/n0IPWbSCDDnsq6bqPPuj3EYpnGeB3rqMaDq3MnyphLHoPKKQjVjprB103qlliqx9nI2U66lVhIqEXkYdF5EURuS4iTxzx/TtE5Ksi0heR9xz67rdE5JqIvCAi/0JmPXtnr2GfwMcsIqRTGXoSdO5BG62h98b1sZGJWcN/pzqqdhlRA+Oj94gN20/vpEXfKJqo5hXjVKEXET/wMeAR4EHgfSLy4KHDXgU+CHzy0LlvA34UeAPwg8BbgB+futbToH3tpQmDlTYyUaqScs5HqoNVSh4J5chP79Qcg/37mWApTyikI2z34yin2q/fRTrViVadGZaHSSz6h4DrSqmXlVJd4FPAY+MHKKVeUUo9DwwPnauACBACwkAQ2J661tOgLfOKJLmQPP1GL9hLLJ2yqPR19lxOf2BTSEfZGTgY3at/vz2T/sATCukoxWESVXfq/js9z5Nh+ZhE6O8Cboy9v6k/OxWl1B8BXwI29b/PK6VeOHyciHxIRK6KyNWdnZ1JLn1+tND64vmJ8nAX0hG2BwmUY64b60HrRbJEQ+4FS9kU0hFuDxMMGg79rrr+FUmbYCkPKKT1hLpT0dnN8RGl6ahXBVcnY0XkzwHfD1zG6hzeJSJvP3ycUuoppdQVpdSV9fV1N6s0smwj6QsTHb6h16IP6g4Jpe4wQqnJyp+WUdCUw3MM/sT6kVswGpzFvv98wy50atNf0B5RkuKC2VlqZZhE6F8D7h57f1l/Ngk/B3xZKVVXStWBzwE/crYqOkyzRI04FzKJiQ4v6LX04pSPvlmkR4B0es2Z651CIR1llyS+dtmZDIi6w4hmXO6QDYDVfvuxEA6433T7qViOoAmWWhkmaelngQdE5D4RCQGPA09PeP1XgR8XkYCIBLEmYu9w3XiJahbPlB7Y9tH7ezXod6avQKPEHikKa7HprzUBdhi9OJUBsVmiRYRcJjP9tQynsp4Ms4eD0dn6GuEJR7SG5eBUoVdK9YEPA5/HEunPKKWuiciTIvIogIi8RURuAu8FPi4i1/TpnwVeAr4OfA34mlLq/3bh/zExg9oOxTOsGBn5SMGRB23QsIJVTovKdYqLKZ1THxxx36hm0ay48RC/TyCWt9444X5rlhgixNNmRLZKBCY5SCn1DPDMoc8+Mvb6WSyXzuHzBsDfmrKOjtKv75xpDXgmFqTqS1tvGkVIXZqu/NoOJQ+XtoUCPvqRnLUeyoGVQ72q1VGapXneEUytQwlnVn41ilRUgouZ+PTXMiwMK+ekk+bumVw3IoI/oS0qByx61SjqDUe8W/EQSDpX/4HuKI1F7x2xzEXrhQPt19OGhmm/1WK1hF4pAu3SmaNSAwk9zHXgQfO3rBTJBQ/XMI9WGDkw9Jdmyayh95hsZo2OCjqyxLdXu23d/y7nWTLMF6sl9J0qftVnlxTrZ1haFss4JJT9LsF+3YpK9MhHD5Bcc84iDLT3KBmL3lM2MlZyvW719tTXUo2SGZGtIKsl9Fqoe+HsmZaWpbLrDJQwnDboSAttM5ghHp5oesQR1tdSVFWM3rRC0W0QGLYpkyJnNqzwjEI6yq5K0a1OH8thjyi9NDQMs2e1hF6vhffH82c6bWMtQZkE7cq0Qq9HBLGzlT8tlzLWypv2tEKhO8p+JDtRVLHBGQq6/YbTjiiHQ0LdCrukuGiEfqVYMaG3HpRg6mxLywqpiLaoprSI9YM6mhz1iI1UhF2S9GvOdFS+M3aUhumwlvgm8U3remuX8TGgG1ojFFitR3/VWanWVtr1ErFXMUzIhn7QhtOmQWieLf2CU9hBXzLt8jw9IjprR2mYjvVEmD2VItSdMuBN338qlnOgVoZFYqWEvqNdF6ncxpnOs6JLk/ha06VB6OmOIr5WmOo6Z+ViOsyuShFoT1d/u6OMZkxUpZcE/D464SzhQWO66OzGfp4iw2qxUkLf3NumrYKsr50tz0w2HqIsaYKd6Syq5t42QyWs5b0VynDATzuYJtIrT5UBsV22XFfJnLcdlQFULGu9mMZ9o0d0EdNRrxwrJfTd6m1rw5EzriEWEbrhNaL9irWV3jlpl7cpE2djBlGJ/WiOgOpNlQGxsbdNV/nJZ42P3mtGQXtTTMi2K1ZHHV87m+vSsPislNAP68Vz76wzjObwMZwqMVi/XpzZGmaxV/pM4afv1m6zR5INE2zjOaGkJc7TBE019qw9fzJ5MyJbNVZK6H2t0rmXlo2WZE4hlNIsUWI2Gz4Ek9ovO8VOU4NRR2WE3mvia5a7pVU5/wZt7co2dRXhwlraqWoZFoSVEvpgZ4+mP3OuPNx2WtfhFFu6Bdq7VH0pEh4GS9lEtVC0p1gi6tcd5Vmiig3OkNJWeG33/ELfr+2wq5JcMiOylWOlhD7WL9MLn2/Dj5j2a9b2ts5dfqS7RzfkzYYjh0lmrZVG1dL56x/s7NIKpE2w1AzIr19koIRWeYotlxtWnqcLKdNRrxqrI/S9NlHVYnjONcQpvdKkdl6hHA6JD6tWyuAZkMlb6ZWbU3RUsV6FbjjrVJUMZ2AjE2ePJL0popsDnV3q/gzhgPt7FRvmi9URejuq85xriHPrltCf26Jql/Ez3J8U9ZiLuSwdFRzFEpyZQY+4qjOMmmCbWXAhGWZPJaeaI4p092jPaERpmC0rI/T2ioPwOaM6N3JpaipKr3a+B81OnzCrqFI7A+J55xjs1R7n7SgN0xH0+6j50/jPG7SnFIlBhcGMRpSG2bIyQl8ubgL7vvazko2F2CM5ig49K3u6/FlFlUaCfiqSRs4ZcFPfszqq83aUhulpB9cInzcNQq9JmC4SN0K/iqyM0Nu+9fQ5ozp9PqHmz5zborInQe1J0VnQDGQIdc5X/73iLeD8HaVhenqRLPFB+VznNvWINpA0HfUqsjJC39JRgbkL59/ztR3MnNuish+07PrsglV64TWi/fPVf9RRmmCbmSGxHKlhDYaDM5+7u6M76jMm9DMsBysj9N3aDn3lY339/Dd6P5Ildk6LqqMDXfIXp9tcfBqG0RzJYfVc59qT0LkLRuhnhT+5jk8UtfLZ3YcV7TpMzHBEaZgdEwm9iDwsIi+KyHUReeKI798hIl8Vkb6IvGfs83eKyHNj/9oi8rMO1n9yGkUqkiQUPH+wkorlyAyrDAdnz3czaJRoqAjJRPLc5U+LL7FOghbtVvPM59rL+nJ5IxSzIpK2jJTS7VtnPrehO+o1034ryalCLyJ+4GPAI8CDwPtE5MFDh70KfBD45PiHSqkvKaXeqJR6I/AuoAl8Yfpqnx1/q0Tdn5nuGol1wtJjr3J294evWaLqm23oeUhPpN7efu3M56pGkQoJAsGQ09UyTEgiawm9vbDgLHT17mi5C3c5WifDYjCJRf8QcF0p9bJSqgt8Cnhs/ACl1CtKqeeBk0zd9wCfU0qd3Zx0gEh3j3YwM901dBqE4jmEMtTZpTll+dNiT6Tu7ZzdIvS3d6lN2VEapiOjrfHG7tmD3gb1HXoEiCQyDtfKsAhMIvR3ATfG3t/Un52Vx4HfOeoLEfmQiFwVkas7O9NvgHwUsUGFfmS6qE7bv7lXPPuDFu3tzTyqdD+69+xBX+HuLu2gCbaZJWs6url1jr2LpVmiIikQk75iFfFkMlZECsAPAZ8/6nul1FNKqStKqSvr684v/6p3+mRUBTVlVGratqjOmEagNxiSVFWG0dkKfVavmGmeMbpXKUWsX6EfMUI/S2zX2+Ace/8GO3u0ZjyiNMyOSYT+NeDusfeX9Wdn4a8Cv6eU6p3xPEfY2muQoTH1ptyZnGVR2TstTcrtapscVXzx2a5htvfK7dXOVv9ap88a1ak7SsOUBMI0JHauNAix/uwS6hlmzyRC/yzwgIjcJyIhLBfM02cs530c47bxgtLOJj5Ro1UL58Wnowr7Z0wjcLtUIiK9kUU2MyIZBvgYnjEn/Va5yRo1E2wzBzT9Z9/SstUdkBpWGERNR72qnCr0Sqk+8GEst8sLwGeUUtdE5EkReRRARN4iIjeB9wIfF5Fr9vkici/WiOD/c6H+E2H71BPTRnWGk/QInHk7t9JtO/3CjJe2+Xw0fCn8rbMJ/e3b2wRkOJqMNsyOTihL5IxBe5uVFjmp4UsYoV9VJlpUrpR6Bnjm0GcfGXv9LJZL56hzX+F8k7eOYa9SSOWmFFoR6oEMwTOmEbA3i0jlZh+V2ApmCJ/RIqzojtLsNTp7+tEs6fqr1No9kpHgROds79W4X5qUZz2iNMyMlYiMtTdFDqWmt0hti0opNfE5dlTpPISf9yJZEsMK7d7kYfT1PbujMsE2s0biebJSY7vanvic3R2ro56H+88wG1ZC6Pt1vUohPv3QdRBZI0OVvebk88r25Kc4UP7UxHJkOZtQtHX6hoBJUTxzQsl1stTYLLcmPqfm1IjWsLCshNCPUvM6sLxR4nmy1Lh1hgdtlAN+Dlat+BPrZKXKZmVyoe/XnOsoDdMRzVwkLD12SpO7D+3lwE6MaA2LyUoIfaC9S8uXgMD04fvB5AWyUmXrDELpb+3SlwCEZ5fnxiacvsAadTbL9clPsjvKc27DaHCOuE6DUClNngahZ3fUpv1WlqUX+ma3T2JQpnPOTcEPE81cICUttsuTZYHsD4ZEenu0gmtzEZWYWLuITxR7xcnX0gfbu3R9UQhGXayZYRKCScsqb5UnD9qbpxGlYTYsvdBvVtpkqTq2hZo9oVWZcJPwnXqHNar052RTbXv4bk+wnkat3bMmb02wzXygrfJOZfIlvoH2LkMEYvNxDxq8Z+mFfqvSJit1x7ZQs9ciN3cnE8pb5TY5qaLmZdis6zFpdO9WxYrqHZhNwecD3X6D+mRpENq9AdHeHp1ACnx+N2tmmGOWXug3K22yUiXoVFSnHv52qpML5Ro1/PMSrKInVPsTpkHYrLRZkxoyLx3VqqPbzzdh0NuWbr/enIwoDbNh6YV+q9wkS5WoU2uI9YM2nDANgh2VOG36BcfQHZVMmC/FGhHVCJpgm/kglKAvIWL9Mo1O/9TDNyttctTMROyKs/RCX9orEZKBc3la7AemWZooaGp7r0ZKmrPPc2Oj/bTBTplO//SgqVuVFjmq89NRrToi9MJr1lr6CVZ+bVZaZKWK3+QpWmmWXuibe9pF4ZRFE11DIaRUhfIEQVMNPek5F8FSAIEw3UCCnFTZrnROPby0t0dUuvPjejIwjOYmXuJruy7NGvrVZumFvmv70p1aWubz0w1lyDFZ0FGr4nBH4wCDSJas1NisnB701XC6ozRMjS+RJzdh+22Xm6xJneCUKboNi83SC/1wlP7AOaFSUUsot6qnP2jzGFVqRfdW2ZogDUK34nBHaZiaUOqC1X4TGBqVvSIBhqb9VpylFvpWd0DITunq4I3uS6yTlRq3yic/aIOh2l8dMUcPWiC5ri3604Vi0Ji/jmrV8Sfy5Hx1bk00otTLgE37rTRLLfRb1TZZatYbB10PweT6RBbVTq1DRukI2jl60AKJdfK+0xNj1Tt9oqOO0rhu5oZYngRNiuXKqYcOTPoDA0su9PaKg4E/DKG4Y9eVeN4SylOE3iq/hkIgOkeRpfEca1RPFXp7DTZghGKe0G7IZvnkoKl2b4C/rZOfmfZbaZZa6LcqbXJSQ0VzzuaZieVIU2e70ji1/CxVBuHMfEUlxnKE6FOpnLwBif37DX1BiKQ9qpzhVLRonxb0drvaIWt31HM0ojR4z1ILvZ3nxud0HvV4Hj9D6uWTg45u6aVtc7O00mbC6N5blRZZqqhodi4Sshk0uv0CnT1a3eNjIez2Gz/HsJosudC3WPfXR5t6O4Z+aLrVnRODprYqLfK+OdyrM25Hx5bo9ofHHmZb9HPXUa06uj1ynLzEcjQiC8YhGPGqdoY5ZKmFfqvSJu+rOW/N6I4j3i9TbR0fhr5ZaXPB15i/PDH691ijeuJOU5uVNhfc6CgN06Hb77SgKTtPkfHPG5Za6G+V26ypqvP+Sf3gZKXK5glr6be062bu/KM6DUJOTl5Lb49IzLB/zohmUMipO4VtVVpc9Nfwzdv9Z/CciYReRB4WkRdF5LqIPHHE9+8Qka+KSF9E3nPou3tE5Asi8oKIfFNE7nWo7qeyW6kSUS3nLZqRRVVj84S19FvlJonhHApl3LboT145tFlpk2EOO6pVx+eHWFbnuzne0LhVaXPBVzftZzhd6EXED3wMeAR4EHifiDx46LBXgQ8CnzziEv8G+KhS6vuBh4DJtzaagnZv4N4WePrBOSmx1GCoaNV28TOYvwctlED5w7qjOl4odsp14sP6/HVUBiSWZyNQP8Wit103pv1WnUks+oeA60qpl5VSXeBTwGPjByilXlFKPQ8cmNnTHUJAKfVFfVxdKdV0puons121JqIA54U2EEaFkuSlytYxFlWp3iGtdEDLvPlIRZB4nov+44Wi2e3ja9vBUiaX+dwRz3Mx0DjVR58aVkz7GSYS+ruAG2Pvb+rPJuF7gLKI/K6I/KmIfFSPEA4gIh8SkasicnVnZ7Kdc07jVln7x8EVi0ZiWS6FGscKpb200yp/zoQeIJalEKwfKxSj+QWYvxGJAWJZcif46Lv9IY16hZDqmPYzuD4ZGwDeDvwq8BbgfiwXzwGUUk8ppa4opa6srzuz5n2rOraG2I0bPZ7ngv8koW+5N6JwglievK9+rI93U284Yh9rmDNieVKqemz7HRjRmvZbeSYR+teAu8feX9afTcJN4Dnt9ukDvw+8+Uw1PCcHhcoFizqWJ+c7/kHbPJA+YA4ftHieNXW8RWiNSOa4o1p14nli/SrlZseajzrEpt7C0j7WsNpMIvTPAg+IyH0iEgIeB56e8PrPAhkRsc30dwHfPHs1z85WpU0h2ADxQyTjfAHxPOmhJZRHBU1tVdpc8M1xnphYnsSwwk69Q29wZ9DUls4TZB07h/VfdWJ5fAzJcLT7zRpRmvYzWJwq9NoS/zDweeAF4DNKqWsi8qSIPAogIm8RkZvAe4GPi8g1fe4Ay23zByLydUCAf+XOf+Ugt8ptLoca1kSUzwUPVSxLfFCm2e1Tbd8ZNHWr0uZyuAmhxHxGJcZyhAcNgqrH7dqdO03dqujfDyBqJvPmjlEsR41bR4wq536OyOApgUkOUko9Azxz6LOPjL1+Fsulc9S5XwTeMEUdz8VWtcUFf929mzyWJzDsEqPDVqVNOho8WH6lRSFQh8icPmQ62nUNa4nlXZnoga+3Km3eFmqCbw38E90mBi/R7ZeldqRFPxrRgnHdGJY3Mnar0ibnc3ENuL2WXo72029W2uT9cxyson+X41ZubFbaXAyYNfRzS2z8/jvadXM53ARfEMIpr2tnmDOWUug7/QHFepf0sOLoFoIHsIXyiA1IhkPFdrXNGtX5HTaPOqrjLEK9amhe67/q6Pa7HG6ebNHHHE7RbVhIllLotyuWzzneL7tnkWoBzPlqd2zpVmx06A0UyUFlfi1iXf9LR0RXtroD9po9K+BrXkckq45uv3vCzSNHlLcqbdZN+gODZimFfrPSwseQUK/inkWqRwqvi7TuiI61LCxFpLvn3ohiWnQHdE+0dYdQ2InOrI5yTuu/6gTCEEpSCN4Zy9HtDynWO6zh4v1vWCiWUui3qm0y1BGUexaNLZTh5h0P2malTZQO/mFnfi366BqIj8uho+rfAhThbtlYhPNMPMcF/53LK2/X2igFiYFJSGewWEqh3xwP33fLogknwR/iUuhOH6m94YOr5U+LzwfRLBcDdwrFVqVNigaiBvNbfwPE8mSpUmp0DwRN2e0Z7e2Z9jMAyyr05RZ3h3XuNLcsGhGI5bjgvzOD5a1Ki4v+urvlO0EsR15q3K616Y8FTW1WTPj8QhDLkRxaifPGN5C5VWkToE+wVzXtZwCWVegrbe6Pab+zmxZNLM8aNeqdPrV2b/TxVqXN/fHW6Ji5JW7lSxkqDgRNbVZavC5id5TGIpxb4nli/TLAAWNjq9IaS39g2s+wpEK/VW1zOeyB0MZzVhpYOOD+2Ky0eV2kPTpmbonlSAzKwGGhaHNfTAv/PHdUq04sR7CzB6g77r+7QrqjNu1nYEmF/la5zV12VKDLFv3RFtVY+oB59pHG84S7Vs75OzsqWyjmuP6rTjyPb9AhTvuO++/PJfR7034GllDo7aVl6/46hNMQCLlXWCxHqLMLMFqiOBxa1tXFQH3+oxJjOfztPXwMDyyx3DTh84uBvZY+cnAt/a1Km3uj+r1pPwNLKPT2pFRWqu7vrBPP4+vWCEl/ZFHtNrt0B0NrMjOen++oxFgeQXEx2BrVv90bsNvoctFfg2AcgtFTLmKYGdot80C8e4ePfn9Ea4TesIRCbwf7pIYerCHWFtXr452R68P+m2EBVjzo3+d7k/v1tzvKNanP9/yCYdR+98Vao/brDYbcrnXYCDYBseIlDCvP0gn9Lb3Zday3577Q6gftgcS+j9T+a0WVznl631FH1R4N/e36p4Zl49+dd3T7XA7vR8fu1DooZSWrI5oxmUcNwBIKvW3ZBDu77luk+kG7L9IaE0rrb7i7N//+UV3/u8eie+36x3rl+R+RrDq6/TYCDYr1Dp3+YNR+GbUAI0qDZyyd0G9W2iTCfnzNkvsWqX6QLkdaByz6oF/wt0rz/6DpjuhSqMntWof+YDj6f1gd5ZzXf9XR0dnrPis473a1sz+iHJRN+xlGLJ3Qb1XavD6lYNjzzHVTCDaotfvUO322Km0uJQNIZwHyjOiO8KK/zmCoKNa7bFXaZGJBfK1d47qZd0Qglrfmg7CMDHtEG+mWTfsZRiyd0G9WWvtriN0W2ugaIKzrvWG3Ki1ulVt8T7JrfT/vPvpAGMKpUV6gzUqLW+U2r0sCvaYRikUgniM5Cnqz2i8W8uNreTCiNSwMSyj0be6LepR+wOeH6BoZVRmVvVVtc3/MDlaZc4seIJYlNRivf4sHEjoqdt5HJAaI5Yj0rKA3u/0KqRDSLJn2M4xYKqHvDYbs1DvWFmrgjUUTz5Mcaou43D4YVboID1osT6w/JvSVNvdGF6ijWnViefytXZLhAFsV6/57faoPamDazzBiqYT+tl5aVgjYUZ0eCH0sb20wAnxzs0q3P+TSIuUZiecJdEpEgj5eLTUo1rvuZ/40OEc8D80ShUyEzYq1nv7+WHf/O4OBCYVeRB4WkRdF5LqIPHHE9+8Qka+KSF9E3nPou4GIPKf/Pe1UxY9iU6+hz/s8TLEby+JrlcgnQvzpq5bgX/DPeS76cWI5pFGikI7y3I0yABvB+ug7w5wTy0GnyuWUn5t7Lbar43mK5nyOyOAZpwq9iPiBjwGPAA8C7xORBw8d9irwQeCTR1yipZR6o/736JT1PRF7adkaVQhEIBR3sziLeB4aRTbSEa7dslw4WakBshgPWiwHzSIbyfCo/vZyPSP0C4Ad9Bbr8OJWjaGCSyGT/sBwkEks+oeA60qpl5VSXeBTwGPjByilXlFKPQ8Mj7qAV9hLyxIDvVemF3lmYnlo7VJIhukPFYCVuji6Zk3WzjvxPAy63JtUo/qvqaqVkC2SnnHlDKcS39/7126/i/aI0rhuDJpJhP4u4MbY+5v6s0mJiMhVEfmyiPzsUQeIyIf0MVd3dnbOcOmD3Kq0iIf8Vo5ur6zReB7UkPuT1sYjAZ8Q6ZUX5yHTVt998f3sh4mhhx2lYTp0+90dbow+yooZkRkO4sVk7OuUUleAnwf+uYi8/vABSqmnlFJXlFJX1tfXz13QVqXNRjqCNIveCa1+mGy/6MVUxJuoXKcYS4MAkIoECLZNsNTCoNvpgn9f6FPDisk8ajjAJEL/GnD32PvL+rOJUEq9pv++DPy/wJvOUL8zsVlpU0hHoVH0zj85SixlCeVGOqLLXxChtKN79UqlQjoKzaLJXLko6PbL66C3SNBHuOtBnifDQjGJ0D8LPCAi94lICHgcmGj1jIisiUhYv84DPwp887yVPQ3bosdLi1o/aBe1RTUqf2FcN9bvlNebme//fgtS/1VHR2enlSX0hXQUae6a9jMc4FShV0r1gQ8DnwdeAD6jlLomIk+KyKMAIvIWEbkJvBf4uIhc06d/P3BVRL4GfAn4J0opV4S+Pxhyu9bm7qRA18Nc6vqBspd0XkqFFksodYeU1flSLmX0iGRROqpVx+eHWJZwd49EOEAhbdrPcCcTJatWSj0DPHPos4+MvX4Wy6Vz+Lz/CvzQlHWciJ16h6GCeyIeR3VqizitKtyT/R4eKvh1VOKCDJ1DCfCHiPb2+J6LCd58OQHPlxen/garrRpFHrovyw9eSsG1Elz4/lnXyjBHLM2uBIV0lD/7jYeRreetmQCvLJpgBEIJAq1d/vDvvROK37Y+XxSLSmdAlGaJL/wPPw61batLN0K/OMSs6NhP/OJbrPd/skBzRAZPWKoUCJGgn7DerNvTGz2Ws9w1sP93kR60+BH1X5SOynCw/bpN6LdM+xkOsFRCD0DTFnoPb/R43lqpApZ/1P5sUYjl9+tt/z8WZY7BYNrPcCpLKPQzEFrtIz1Q/iJZ9DoNArD//1ik+q86sRy0dmE4NO1nOJLlE/pGEcQHkYx3ZWof6ah8+7NFIZ6HhnHdLCw6OpvWnmk/w5Esn9A3ixDNgs/D/5rtI1XKch2FEtYk7aIQy0O3Bv3OvlBEFyAhm8HCNiqapcWcIzK4zhIK/QyClWJ56Leh27A6mkV7yOyYg2bJGpFE18C/NAuylp9R+xUXc47I4DrLJ/SNGQQrxQ49aIsm9HZ9G8XF7KhWncPt5wtCODXbOhnmiuUT+lnkabGtp0ZJl79g1tRo6F/0Nk+QwRnuaD+TedRwkOUT+llY1Ad8pAuYZ8TumJq71r9F66hWnfih+8+0n+EQyyX0w4G18sBroT3sI120zIH272VcN4tJIAyh5P6I0rSf4RDLJfStPUDNYDJWP1jlG1ZU4qI9aNEMINDY8Tbzp8E5YtnFnSMyuM5yCf2sgkXCKWsCbOfPdPkLNnTWGRDZfRmGfTP0X0T03sULOUdkcJ3lEvpZRaWKWA9X8VvW+0V80GJj9V+0jspgtVl9G9oV036GO1gyoZ9hVGAsv5+5chEftPhY/RdtjsFgtV/pJf3atJ/hIMsl9LNMPxDLwqCz/3rROFB/IxQLh2k/wwksl9DPMvx7fBSxqK6bo14bFgPTfoYTWC6hbxStidFAyPuy7YdrUaMSxzsnYxEuHotuaBhcZbmEfpZLA+2Ha1GjEu2OKhiDUGy2dTGcnZjpqA3Hs2RCP8OlZbZfflGtKVsczLB/MRkXd5N51HCI5RL6WSQ0s4mNWfSLiL1Sw6zYWEzsdjOZRw1HMJHQi8jDIvKiiFwXkSeO+P4dIvJVEemLyHuO+D4lIjdF5H91otLHMsvwb9uSX1iLPn/wr2GxMO1nOIFThV5E/MDHgEeAB4H3iciDhw57Ffgg8MljLvMbwB+ev5oToJTORT8joV94i37B67/qhJPgD5n2MxzJJBb9Q8B1pdTLSqku8CngsfEDlFKvKKWeB4aHTxaRvwBcBL7gQH2Pp1ODQXeGrpsF93Hb9V/UEcmqI2K1oWk/wxFM4sy7C7gx9v4m8NZJLi4iPuCfAr8A/OQJx30I+BDAPffcM8ml72TYhx/8K3DxB853/rTE8/DOfwA/+JdnU/60BMLwU78Br3/XrGtiOC/v+oeQuXvWtTDMIW7P2vwK8IxS6qacsORQKfUU8BTAlStX1LlKimXhPZ8416mOIAI//muzK98JfvS/m3UNDNPwpvfPugaGOWUSoX8NGDcTLuvPJuFHgLeLyK8ACSAkInWl1B0TugaDwWBwh0mE/lngARG5D0vgHwd+fpKLK6VGJoaIfBC4YkTeYDAYvOXUyVilVB/4MPB54AXgM0qpayLypIg8CiAibxGRm8B7gY+LyDU3K20wGAyGyRGlzucSd4srV66oq1evzroaBoPBsFCIyFeUUleO+m65ImMNBoPBcAdG6A0Gg2HJMUJvMBgMS44ReoPBYFhy5m4yVkR2gO9OcYk8UHSoOm5g6jcdpn7TYeo3HfNcv9cppdaP+mLuhH5aROTqcTPP84Cp33SY+k2Hqd90zHv9jsO4bgwGg2HJMUJvMBgMS84yCv1Ts67AKZj6TYep33SY+k3HvNfvSJbOR28wGAyGgyyjRW8wGAyGMYzQGwwGw5KzkEI/wWblYRH5tP7+j0XkXg/rdreIfElEviki10Tkvz/imJ8QkYqIPKf/fcSr+o3V4RUR+bou/44scmLxL/Rv+LyIvNnDun3v2G/znIhUReTvHjrG099QRD4hIrdF5Btjn2VF5Isi8m39d+2Ycz+gj/m2iHzAw/p9VET+TLff74lI5phzT7wXXKzfPxaR18ba8GeOOffE593F+n16rG6viMhzx5zr+u83NUqphfoH+IGXgPuBEPA14MFDx/wK8L/r148Dn/awfgXgzfp1EvjWEfX7CeA/zfh3fAXIn/D9zwCfAwT4YeCPZ9jeW1jBIDP7DYF3AG8GvjH22W8BT+jXTwC/ecR5WeBl/XdNv17zqH7vBgL69W8eVb9J7gUX6/ePgV+doP1PfN7dqt+h7/8p8JFZ/X7T/ltEi/7Uzcr1+3+tX38W+Ity0l6GDqKU2lRKfVW/rmHl8L/Li7Id5jHg3yiLLwMZESnMoB5/EXhJKTVNtPTUKKX+ENg99PH4ffavgZ894tSfBr6olNpVSu0BXwQe9qJ+SqkvKGs/CYAvY+0ONxOO+f0mYZLnfWpOqp/Wjr8K/I7T5XrFIgr9UZuVHxbS0TH6Rq8AOU9qN4Z2Gb0J+OMjvv4REfmaiHxORGaxo7kCviAiX9Gbsx9mkt/ZCx7n+Ads1r/hRaXUpn69BVw84ph5+R1/CWuEdhSn3Qtu8mHtWvrEMa6vefj93g5sK6W+fcz3s/z9JmIRhX4hEJEE8B+Av6uUqh76+qtYrog/D/wvwO97XD2AH1NKvRl4BPg7IvKOGdThREQkBDwK/Psjvp6H33CEssbwc7lWWUR+HegD/+6YQ2Z1L/xvwOuBNwKbWO6ReeR9nGzNz/2ztIhCP8lm5aNjRCQApIGSJ7Wzygxiify/U0r97uHvlVJVpVRdv34GCIpI3qv66XJf039vA7+HNUQeZ5pN4Z3iEeCrSqntw1/Mw28IbNvuLP339hHHzPR3FGuv5r8EvF93Rncwwb3gCkqpbaXUQCk1BP7VMeXO+vcLAH8Z+PRxx8zq9zsLiyj0o83KtcX3OPD0oWOeBuzVDe8B/vNxN7nTaH/e/wG8oJT6Z8ccs2HPGYjIQ1jt4GVHFBeRpP0aa9LuG4cOexr463r1zQ8DlTE3hVcca0nN+jfUjN9nHwD+4xHHfB54t4isadfEu/VnriMiDwN/D3hUKdU85phJ7gW36jc+5/Nzx5Q7yfPuJj8J/JlS6uZRX87y9zsTs54NPs8/rBUh38Kajf91/dmTWDc0QARruH8d+BPgfg/r9mNYQ/jngef0v58Bfhn4ZX3Mh4FrWCsIvgy8zePf735d9td0PezfcLyOAnxM/8ZfB654XMc4lnCnxz6b2W+I1eFsAj0sP/HfwJr3+QPg28D/A2T1sVeA3x4795f0vXgd+EUP63cdy79t34f2SrRLwDMn3Qse1e/f6nvreSzxLhyun35/x/PuRf305/+nfc+NHev57zftP5MCwWAwGJacRXTdGAwGg+EMGKE3GAyGJccIvcFgMCw5RugNBoNhyTFCbzAYDEuOEXqDwWBYcozQGwwGw5Lz/wOQyVulfX02LAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.279816, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276095, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302537, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261553, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258660, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.199851, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252869, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.316060, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261071, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294550, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.328531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265298, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300449, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279637, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.326617, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225565, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283718, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239371, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246414, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322298, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.321196, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288661, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274276, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291370, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303885, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270436, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.316613, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298564, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261651, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301345, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.316311, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319727, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277209, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263782, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303246, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.89)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.331153, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319485, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310202, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.294249, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.267769, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.310169, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.272425, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.230343, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.079480, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.192102, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.333190, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.397284, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.707860, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.136497, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.780975, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.959194, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.992249, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.891989, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.508097, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.516502, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.015787, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.349749, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.597977, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.426765, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 2.028993, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.541714, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.523968, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.470031, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.042223, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.320444, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 2.084809, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.568773, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.058103, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.630199, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.321790, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.364429, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.849007, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.756186, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.169528, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.174673, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.771525, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.016340, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.564313, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.568751, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.372781, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.189267, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.451450, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.564430, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.567166, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.301771, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.691307, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.959121, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.880799, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.135335, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.541687, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.880920, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.278346, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.596572, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.636427, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.263676, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.280011, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.690119, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.302855, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.474342, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.226216, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.692227, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.602363, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.222041, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.102354, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.697068, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.657005, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.672257, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.284474, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.514149, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.362322, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.622598, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.598950, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.636689, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.650404, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.303066, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.157793, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.888470, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.301639, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.323328, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.456056, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.592102, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.027894, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.606007, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.235845, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.272714, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.554669, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249534, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.371096, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.567070, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.263040, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.267806, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.385452, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.980953, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.259739, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.321781, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.566508, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.222777, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.633162, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.728482, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.559565, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.533431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.165641, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.503011, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.635184, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.381262, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.324540, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.125684, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.159176, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.218835, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.268056, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097033, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.141135, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.147408, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.114398, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.302670, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.312551, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.288891, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.430106, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219437, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.465110, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.194220, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.171476, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.133824, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.622532, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126915, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.504876, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.308758, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.242236, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.316953, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.127420, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.336672, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.326583, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391557, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.242850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.171301, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.321793, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.568719, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.568855, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.312827, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.617106, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.217849, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.413417, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.368696, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.375302, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.392779, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.314016, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.270437, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.277316, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.062609, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.684136, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.849816, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.301826, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.727921, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.615777, Train accuracy: 0.600000, val accuracy: 0.133333\n",
      "Loss: 1.241614, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 1.549091, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.273008, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.217543, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.891656, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.367313, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.070984, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.172215, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.405956, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.579181, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.100012, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 1000, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=2e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.313215, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 1, Loss: 2.271794, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 2, Loss: 2.243684, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 3, Loss: 2.198240, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 4, Loss: 2.189183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 5, Loss: 2.226161, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 6, Loss: 2.314014, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 7, Loss: 2.290646, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 8, Loss: 2.198725, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 9, Loss: 2.305571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 10, Loss: 2.269494, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 11, Loss: 2.224045, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 12, Loss: 2.098623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 13, Loss: 2.304180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 14, Loss: 2.380452, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 15, Loss: 2.273963, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 16, Loss: 2.276056, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 17, Loss: 2.215086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 18, Loss: 2.322621, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 19, Loss: 2.258152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 20, Loss: 2.153668, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 21, Loss: 2.251784, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 22, Loss: 2.172575, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 23, Loss: 2.181496, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 24, Loss: 2.258790, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 25, Loss: 2.186645, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 26, Loss: 2.173274, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch: 27, Loss: 2.280868, Train accuracy: 0.198444, val accuracy: 0.206000\n",
      "Epoch: 28, Loss: 2.044850, Train accuracy: 0.200222, val accuracy: 0.213000\n",
      "Epoch: 29, Loss: 2.175314, Train accuracy: 0.205111, val accuracy: 0.212000\n",
      "Epoch: 30, Loss: 2.058662, Train accuracy: 0.211222, val accuracy: 0.220000\n",
      "Epoch: 31, Loss: 2.270706, Train accuracy: 0.215333, val accuracy: 0.225000\n",
      "Epoch: 32, Loss: 2.012289, Train accuracy: 0.221667, val accuracy: 0.228000\n",
      "Epoch: 33, Loss: 2.206273, Train accuracy: 0.230111, val accuracy: 0.231000\n",
      "Epoch: 34, Loss: 2.191561, Train accuracy: 0.235000, val accuracy: 0.240000\n",
      "Epoch: 35, Loss: 2.125523, Train accuracy: 0.240333, val accuracy: 0.244000\n",
      "Epoch: 36, Loss: 2.108415, Train accuracy: 0.246111, val accuracy: 0.249000\n",
      "Epoch: 37, Loss: 2.195398, Train accuracy: 0.250778, val accuracy: 0.251000\n",
      "Epoch: 38, Loss: 1.991486, Train accuracy: 0.254333, val accuracy: 0.257000\n",
      "Epoch: 39, Loss: 2.183703, Train accuracy: 0.261000, val accuracy: 0.262000\n",
      "Epoch: 40, Loss: 2.280517, Train accuracy: 0.262889, val accuracy: 0.262000\n",
      "Epoch: 41, Loss: 2.137178, Train accuracy: 0.267889, val accuracy: 0.266000\n",
      "Epoch: 42, Loss: 2.015069, Train accuracy: 0.271444, val accuracy: 0.270000\n",
      "Epoch: 43, Loss: 2.115068, Train accuracy: 0.271778, val accuracy: 0.269000\n",
      "Epoch: 44, Loss: 2.081353, Train accuracy: 0.274889, val accuracy: 0.274000\n",
      "Epoch: 45, Loss: 2.109959, Train accuracy: 0.275222, val accuracy: 0.276000\n",
      "Epoch: 46, Loss: 2.026163, Train accuracy: 0.276333, val accuracy: 0.277000\n",
      "Epoch: 47, Loss: 2.069762, Train accuracy: 0.276444, val accuracy: 0.277000\n",
      "Epoch: 48, Loss: 2.008134, Train accuracy: 0.279000, val accuracy: 0.282000\n",
      "Epoch: 49, Loss: 2.012312, Train accuracy: 0.279667, val accuracy: 0.279000\n",
      "Epoch: 50, Loss: 2.053824, Train accuracy: 0.282667, val accuracy: 0.281000\n",
      "Epoch: 51, Loss: 2.154535, Train accuracy: 0.282778, val accuracy: 0.283000\n",
      "Epoch: 52, Loss: 1.868592, Train accuracy: 0.283889, val accuracy: 0.285000\n",
      "Epoch: 53, Loss: 2.164983, Train accuracy: 0.287222, val accuracy: 0.291000\n",
      "Epoch: 54, Loss: 2.130112, Train accuracy: 0.289444, val accuracy: 0.292000\n",
      "Epoch: 55, Loss: 1.952656, Train accuracy: 0.290889, val accuracy: 0.294000\n",
      "Epoch: 56, Loss: 1.990170, Train accuracy: 0.294222, val accuracy: 0.294000\n",
      "Epoch: 57, Loss: 2.029770, Train accuracy: 0.297222, val accuracy: 0.299000\n",
      "Epoch: 58, Loss: 1.960153, Train accuracy: 0.299889, val accuracy: 0.304000\n",
      "Epoch: 59, Loss: 2.045909, Train accuracy: 0.304000, val accuracy: 0.306000\n",
      "Epoch: 60, Loss: 1.880396, Train accuracy: 0.306556, val accuracy: 0.309000\n",
      "Epoch: 61, Loss: 1.808344, Train accuracy: 0.312667, val accuracy: 0.316000\n",
      "Epoch: 62, Loss: 1.991635, Train accuracy: 0.316000, val accuracy: 0.320000\n",
      "Epoch: 63, Loss: 2.105713, Train accuracy: 0.324111, val accuracy: 0.324000\n",
      "Epoch: 64, Loss: 1.988016, Train accuracy: 0.328000, val accuracy: 0.329000\n",
      "Epoch: 65, Loss: 1.940949, Train accuracy: 0.334000, val accuracy: 0.334000\n",
      "Epoch: 66, Loss: 2.098204, Train accuracy: 0.340222, val accuracy: 0.340000\n",
      "Epoch: 67, Loss: 2.058601, Train accuracy: 0.343667, val accuracy: 0.348000\n",
      "Epoch: 68, Loss: 1.860872, Train accuracy: 0.347778, val accuracy: 0.347000\n",
      "Epoch: 69, Loss: 1.907491, Train accuracy: 0.353111, val accuracy: 0.349000\n",
      "Epoch: 70, Loss: 1.950763, Train accuracy: 0.358222, val accuracy: 0.359000\n",
      "Epoch: 71, Loss: 2.036856, Train accuracy: 0.360111, val accuracy: 0.356000\n",
      "Epoch: 72, Loss: 2.030695, Train accuracy: 0.366000, val accuracy: 0.361000\n",
      "Epoch: 73, Loss: 2.126364, Train accuracy: 0.367222, val accuracy: 0.364000\n",
      "Epoch: 74, Loss: 2.100726, Train accuracy: 0.372778, val accuracy: 0.372000\n",
      "Epoch: 75, Loss: 2.069849, Train accuracy: 0.373222, val accuracy: 0.370000\n",
      "Epoch: 76, Loss: 1.925520, Train accuracy: 0.377889, val accuracy: 0.374000\n",
      "Epoch: 77, Loss: 1.937274, Train accuracy: 0.381778, val accuracy: 0.378000\n",
      "Epoch: 78, Loss: 1.924464, Train accuracy: 0.382556, val accuracy: 0.375000\n",
      "Epoch: 79, Loss: 2.008015, Train accuracy: 0.386111, val accuracy: 0.380000\n",
      "Epoch: 80, Loss: 1.936680, Train accuracy: 0.391444, val accuracy: 0.381000\n",
      "Epoch: 81, Loss: 1.768339, Train accuracy: 0.391111, val accuracy: 0.387000\n",
      "Epoch: 82, Loss: 1.857939, Train accuracy: 0.393000, val accuracy: 0.387000\n",
      "Epoch: 83, Loss: 1.961955, Train accuracy: 0.397556, val accuracy: 0.387000\n",
      "Epoch: 84, Loss: 1.974139, Train accuracy: 0.397333, val accuracy: 0.388000\n",
      "Epoch: 85, Loss: 2.171905, Train accuracy: 0.398444, val accuracy: 0.390000\n",
      "Epoch: 86, Loss: 2.106940, Train accuracy: 0.401778, val accuracy: 0.396000\n",
      "Epoch: 87, Loss: 1.929313, Train accuracy: 0.404778, val accuracy: 0.395000\n",
      "Epoch: 88, Loss: 1.703684, Train accuracy: 0.407111, val accuracy: 0.395000\n",
      "Epoch: 89, Loss: 1.829729, Train accuracy: 0.408778, val accuracy: 0.402000\n",
      "Epoch: 90, Loss: 1.958910, Train accuracy: 0.411111, val accuracy: 0.403000\n",
      "Epoch: 91, Loss: 2.063860, Train accuracy: 0.413667, val accuracy: 0.402000\n",
      "Epoch: 92, Loss: 2.033017, Train accuracy: 0.417000, val accuracy: 0.408000\n",
      "Epoch: 93, Loss: 1.712584, Train accuracy: 0.419889, val accuracy: 0.408000\n",
      "Epoch: 94, Loss: 1.919115, Train accuracy: 0.422000, val accuracy: 0.416000\n",
      "Epoch: 95, Loss: 1.851209, Train accuracy: 0.426444, val accuracy: 0.420000\n",
      "Epoch: 96, Loss: 2.110515, Train accuracy: 0.426222, val accuracy: 0.416000\n",
      "Epoch: 97, Loss: 2.029160, Train accuracy: 0.427778, val accuracy: 0.419000\n",
      "Epoch: 98, Loss: 2.003053, Train accuracy: 0.428111, val accuracy: 0.423000\n",
      "Epoch: 99, Loss: 1.930648, Train accuracy: 0.433889, val accuracy: 0.426000\n",
      "Epoch: 100, Loss: 1.893021, Train accuracy: 0.434444, val accuracy: 0.425000\n",
      "Epoch: 101, Loss: 1.976371, Train accuracy: 0.436222, val accuracy: 0.432000\n",
      "Epoch: 102, Loss: 1.868410, Train accuracy: 0.438222, val accuracy: 0.431000\n",
      "Epoch: 103, Loss: 1.790020, Train accuracy: 0.440667, val accuracy: 0.433000\n",
      "Epoch: 104, Loss: 1.866509, Train accuracy: 0.441000, val accuracy: 0.429000\n",
      "Epoch: 105, Loss: 1.675871, Train accuracy: 0.442000, val accuracy: 0.434000\n",
      "Epoch: 106, Loss: 1.790759, Train accuracy: 0.446778, val accuracy: 0.440000\n",
      "Epoch: 107, Loss: 1.801593, Train accuracy: 0.447778, val accuracy: 0.434000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Loss: 1.949311, Train accuracy: 0.450333, val accuracy: 0.441000\n",
      "Epoch: 109, Loss: 1.995691, Train accuracy: 0.451333, val accuracy: 0.442000\n",
      "Epoch: 110, Loss: 1.796316, Train accuracy: 0.454333, val accuracy: 0.445000\n",
      "Epoch: 111, Loss: 1.957700, Train accuracy: 0.454444, val accuracy: 0.443000\n",
      "Epoch: 112, Loss: 1.940085, Train accuracy: 0.455889, val accuracy: 0.446000\n",
      "Epoch: 113, Loss: 1.950080, Train accuracy: 0.457778, val accuracy: 0.451000\n",
      "Epoch: 114, Loss: 1.829501, Train accuracy: 0.459333, val accuracy: 0.452000\n",
      "Epoch: 115, Loss: 2.009002, Train accuracy: 0.460444, val accuracy: 0.453000\n",
      "Epoch: 116, Loss: 1.723678, Train accuracy: 0.462333, val accuracy: 0.456000\n",
      "Epoch: 117, Loss: 1.921634, Train accuracy: 0.463778, val accuracy: 0.459000\n",
      "Epoch: 118, Loss: 1.873470, Train accuracy: 0.466667, val accuracy: 0.461000\n",
      "Epoch: 119, Loss: 1.975975, Train accuracy: 0.467333, val accuracy: 0.456000\n",
      "Epoch: 120, Loss: 1.882789, Train accuracy: 0.467889, val accuracy: 0.463000\n",
      "Epoch: 121, Loss: 1.629764, Train accuracy: 0.469667, val accuracy: 0.462000\n",
      "Epoch: 122, Loss: 1.736777, Train accuracy: 0.474000, val accuracy: 0.465000\n",
      "Epoch: 123, Loss: 1.829282, Train accuracy: 0.473444, val accuracy: 0.466000\n",
      "Epoch: 124, Loss: 1.861355, Train accuracy: 0.474333, val accuracy: 0.464000\n",
      "Epoch: 125, Loss: 1.648896, Train accuracy: 0.475222, val accuracy: 0.465000\n",
      "Epoch: 126, Loss: 1.846480, Train accuracy: 0.476556, val accuracy: 0.470000\n",
      "Epoch: 127, Loss: 1.826070, Train accuracy: 0.478556, val accuracy: 0.466000\n",
      "Epoch: 128, Loss: 1.649176, Train accuracy: 0.479000, val accuracy: 0.469000\n",
      "Epoch: 129, Loss: 2.015072, Train accuracy: 0.480333, val accuracy: 0.470000\n",
      "Epoch: 130, Loss: 2.133433, Train accuracy: 0.481667, val accuracy: 0.469000\n",
      "Epoch: 131, Loss: 1.863629, Train accuracy: 0.482444, val accuracy: 0.468000\n",
      "Epoch: 132, Loss: 2.015984, Train accuracy: 0.484556, val accuracy: 0.467000\n",
      "Epoch: 133, Loss: 1.937183, Train accuracy: 0.485111, val accuracy: 0.475000\n",
      "Epoch: 134, Loss: 1.849209, Train accuracy: 0.485667, val accuracy: 0.470000\n",
      "Epoch: 135, Loss: 1.519560, Train accuracy: 0.487556, val accuracy: 0.475000\n",
      "Epoch: 136, Loss: 1.465871, Train accuracy: 0.488222, val accuracy: 0.473000\n",
      "Epoch: 137, Loss: 1.929891, Train accuracy: 0.489556, val accuracy: 0.476000\n",
      "Epoch: 138, Loss: 1.623931, Train accuracy: 0.489778, val accuracy: 0.477000\n",
      "Epoch: 139, Loss: 1.775721, Train accuracy: 0.491556, val accuracy: 0.482000\n",
      "Epoch: 140, Loss: 1.925594, Train accuracy: 0.492333, val accuracy: 0.483000\n",
      "Epoch: 141, Loss: 1.920027, Train accuracy: 0.493556, val accuracy: 0.482000\n",
      "Epoch: 142, Loss: 1.983057, Train accuracy: 0.494444, val accuracy: 0.486000\n",
      "Epoch: 143, Loss: 1.729109, Train accuracy: 0.496222, val accuracy: 0.484000\n",
      "Epoch: 144, Loss: 1.859870, Train accuracy: 0.495444, val accuracy: 0.487000\n",
      "Epoch: 145, Loss: 1.692708, Train accuracy: 0.497000, val accuracy: 0.490000\n",
      "Epoch: 146, Loss: 1.959577, Train accuracy: 0.497667, val accuracy: 0.487000\n",
      "Epoch: 147, Loss: 1.731540, Train accuracy: 0.497667, val accuracy: 0.488000\n",
      "Epoch: 148, Loss: 1.797135, Train accuracy: 0.498333, val accuracy: 0.489000\n",
      "Epoch: 149, Loss: 1.673198, Train accuracy: 0.499667, val accuracy: 0.491000\n",
      "Epoch: 150, Loss: 1.989981, Train accuracy: 0.500889, val accuracy: 0.491000\n",
      "Epoch: 151, Loss: 1.839776, Train accuracy: 0.500444, val accuracy: 0.495000\n",
      "Epoch: 152, Loss: 1.789320, Train accuracy: 0.501444, val accuracy: 0.494000\n",
      "Epoch: 153, Loss: 1.663136, Train accuracy: 0.502000, val accuracy: 0.497000\n",
      "Epoch: 154, Loss: 1.703373, Train accuracy: 0.503333, val accuracy: 0.500000\n",
      "Epoch: 155, Loss: 1.941149, Train accuracy: 0.503111, val accuracy: 0.502000\n",
      "Epoch: 156, Loss: 1.900349, Train accuracy: 0.505111, val accuracy: 0.504000\n",
      "Epoch: 157, Loss: 1.872357, Train accuracy: 0.504889, val accuracy: 0.503000\n",
      "Epoch: 158, Loss: 1.795813, Train accuracy: 0.505444, val accuracy: 0.507000\n",
      "Epoch: 159, Loss: 1.980357, Train accuracy: 0.506667, val accuracy: 0.507000\n",
      "Epoch: 160, Loss: 1.701881, Train accuracy: 0.506111, val accuracy: 0.510000\n",
      "Epoch: 161, Loss: 1.771393, Train accuracy: 0.507556, val accuracy: 0.511000\n",
      "Epoch: 162, Loss: 1.912365, Train accuracy: 0.509222, val accuracy: 0.511000\n",
      "Epoch: 163, Loss: 1.946809, Train accuracy: 0.510556, val accuracy: 0.510000\n",
      "Epoch: 164, Loss: 1.950092, Train accuracy: 0.510111, val accuracy: 0.513000\n",
      "Epoch: 165, Loss: 2.006351, Train accuracy: 0.510444, val accuracy: 0.512000\n",
      "Epoch: 166, Loss: 1.796904, Train accuracy: 0.512778, val accuracy: 0.513000\n",
      "Epoch: 167, Loss: 1.855096, Train accuracy: 0.512889, val accuracy: 0.516000\n",
      "Epoch: 168, Loss: 1.974671, Train accuracy: 0.511889, val accuracy: 0.514000\n",
      "Epoch: 169, Loss: 1.788965, Train accuracy: 0.513000, val accuracy: 0.513000\n",
      "Epoch: 170, Loss: 2.149999, Train accuracy: 0.514444, val accuracy: 0.515000\n",
      "Epoch: 171, Loss: 1.838903, Train accuracy: 0.514778, val accuracy: 0.518000\n",
      "Epoch: 172, Loss: 1.918272, Train accuracy: 0.514778, val accuracy: 0.513000\n",
      "Epoch: 173, Loss: 2.008469, Train accuracy: 0.517000, val accuracy: 0.518000\n",
      "Epoch: 174, Loss: 1.864134, Train accuracy: 0.515556, val accuracy: 0.519000\n",
      "Epoch: 175, Loss: 1.835985, Train accuracy: 0.516556, val accuracy: 0.521000\n",
      "Epoch: 176, Loss: 1.669481, Train accuracy: 0.517111, val accuracy: 0.521000\n",
      "Epoch: 177, Loss: 1.959586, Train accuracy: 0.518000, val accuracy: 0.519000\n",
      "Epoch: 178, Loss: 1.697239, Train accuracy: 0.518889, val accuracy: 0.519000\n",
      "Epoch: 179, Loss: 1.767665, Train accuracy: 0.517556, val accuracy: 0.521000\n",
      "Epoch: 180, Loss: 1.684332, Train accuracy: 0.519000, val accuracy: 0.522000\n",
      "Epoch: 181, Loss: 1.844367, Train accuracy: 0.519444, val accuracy: 0.523000\n",
      "Epoch: 182, Loss: 1.441904, Train accuracy: 0.521444, val accuracy: 0.525000\n",
      "Epoch: 183, Loss: 1.843781, Train accuracy: 0.520333, val accuracy: 0.524000\n",
      "Epoch: 184, Loss: 2.014089, Train accuracy: 0.521222, val accuracy: 0.522000\n",
      "Epoch: 185, Loss: 1.737945, Train accuracy: 0.521333, val accuracy: 0.523000\n",
      "Epoch: 186, Loss: 2.083065, Train accuracy: 0.523111, val accuracy: 0.521000\n",
      "Epoch: 187, Loss: 1.717833, Train accuracy: 0.522444, val accuracy: 0.523000\n",
      "Epoch: 188, Loss: 1.810527, Train accuracy: 0.522889, val accuracy: 0.522000\n",
      "Epoch: 189, Loss: 1.780213, Train accuracy: 0.523444, val accuracy: 0.526000\n",
      "Epoch: 190, Loss: 1.771775, Train accuracy: 0.524667, val accuracy: 0.526000\n",
      "Epoch: 191, Loss: 1.864147, Train accuracy: 0.525000, val accuracy: 0.532000\n",
      "Epoch: 192, Loss: 1.891815, Train accuracy: 0.524889, val accuracy: 0.529000\n",
      "Epoch: 193, Loss: 1.769659, Train accuracy: 0.526000, val accuracy: 0.528000\n",
      "Epoch: 194, Loss: 1.828615, Train accuracy: 0.526000, val accuracy: 0.529000\n",
      "Epoch: 195, Loss: 1.820787, Train accuracy: 0.526556, val accuracy: 0.531000\n",
      "Epoch: 196, Loss: 1.850762, Train accuracy: 0.528000, val accuracy: 0.533000\n",
      "Epoch: 197, Loss: 1.904244, Train accuracy: 0.528222, val accuracy: 0.534000\n",
      "Epoch: 198, Loss: 1.562401, Train accuracy: 0.529667, val accuracy: 0.535000\n",
      "Epoch: 199, Loss: 1.766721, Train accuracy: 0.529778, val accuracy: 0.535000\n",
      "Epoch: 200, Loss: 1.927622, Train accuracy: 0.529889, val accuracy: 0.536000\n",
      "Epoch: 201, Loss: 1.493249, Train accuracy: 0.530889, val accuracy: 0.537000\n",
      "Epoch: 202, Loss: 1.663907, Train accuracy: 0.532000, val accuracy: 0.537000\n",
      "Epoch: 203, Loss: 1.720629, Train accuracy: 0.532111, val accuracy: 0.537000\n",
      "Epoch: 204, Loss: 1.707088, Train accuracy: 0.532111, val accuracy: 0.539000\n",
      "Epoch: 205, Loss: 1.859608, Train accuracy: 0.532111, val accuracy: 0.540000\n",
      "Epoch: 206, Loss: 1.793644, Train accuracy: 0.532556, val accuracy: 0.539000\n",
      "Epoch: 207, Loss: 1.905352, Train accuracy: 0.533778, val accuracy: 0.541000\n",
      "Epoch: 208, Loss: 1.817341, Train accuracy: 0.533111, val accuracy: 0.541000\n",
      "Epoch: 209, Loss: 1.852112, Train accuracy: 0.534222, val accuracy: 0.542000\n",
      "Epoch: 210, Loss: 2.061314, Train accuracy: 0.534111, val accuracy: 0.543000\n",
      "Epoch: 211, Loss: 1.988678, Train accuracy: 0.534333, val accuracy: 0.543000\n",
      "Epoch: 212, Loss: 1.942603, Train accuracy: 0.534667, val accuracy: 0.542000\n",
      "Epoch: 213, Loss: 2.063544, Train accuracy: 0.534889, val accuracy: 0.543000\n",
      "Epoch: 214, Loss: 1.835803, Train accuracy: 0.535222, val accuracy: 0.541000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 215, Loss: 1.756757, Train accuracy: 0.535333, val accuracy: 0.544000\n",
      "Epoch: 216, Loss: 1.789471, Train accuracy: 0.536111, val accuracy: 0.542000\n",
      "Epoch: 217, Loss: 1.763937, Train accuracy: 0.536000, val accuracy: 0.544000\n",
      "Epoch: 218, Loss: 1.646639, Train accuracy: 0.536889, val accuracy: 0.539000\n",
      "Epoch: 219, Loss: 1.711820, Train accuracy: 0.537222, val accuracy: 0.541000\n",
      "Epoch: 220, Loss: 1.823619, Train accuracy: 0.537000, val accuracy: 0.542000\n",
      "Epoch: 221, Loss: 1.682347, Train accuracy: 0.537111, val accuracy: 0.543000\n",
      "Epoch: 222, Loss: 1.891623, Train accuracy: 0.537333, val accuracy: 0.541000\n",
      "Epoch: 223, Loss: 1.905200, Train accuracy: 0.537111, val accuracy: 0.542000\n",
      "Epoch: 224, Loss: 1.826172, Train accuracy: 0.537667, val accuracy: 0.545000\n",
      "Epoch: 225, Loss: 1.934972, Train accuracy: 0.538000, val accuracy: 0.544000\n",
      "Epoch: 226, Loss: 1.675747, Train accuracy: 0.538778, val accuracy: 0.542000\n",
      "Epoch: 227, Loss: 1.835156, Train accuracy: 0.539000, val accuracy: 0.543000\n",
      "Epoch: 228, Loss: 1.776562, Train accuracy: 0.539333, val accuracy: 0.544000\n",
      "Epoch: 229, Loss: 1.880332, Train accuracy: 0.539333, val accuracy: 0.543000\n",
      "Epoch: 230, Loss: 1.744214, Train accuracy: 0.540000, val accuracy: 0.543000\n",
      "Epoch: 231, Loss: 1.831320, Train accuracy: 0.539889, val accuracy: 0.543000\n",
      "Epoch: 232, Loss: 1.695232, Train accuracy: 0.539667, val accuracy: 0.544000\n",
      "Epoch: 233, Loss: 1.631488, Train accuracy: 0.540333, val accuracy: 0.544000\n",
      "Epoch: 234, Loss: 1.766240, Train accuracy: 0.540778, val accuracy: 0.544000\n",
      "Epoch: 235, Loss: 1.706156, Train accuracy: 0.541333, val accuracy: 0.545000\n",
      "Epoch: 236, Loss: 1.761601, Train accuracy: 0.541667, val accuracy: 0.546000\n",
      "Epoch: 237, Loss: 1.616975, Train accuracy: 0.541556, val accuracy: 0.546000\n",
      "Epoch: 238, Loss: 1.819850, Train accuracy: 0.542333, val accuracy: 0.546000\n",
      "Epoch: 239, Loss: 1.613766, Train accuracy: 0.542333, val accuracy: 0.546000\n",
      "Epoch: 240, Loss: 1.736763, Train accuracy: 0.542333, val accuracy: 0.546000\n",
      "Epoch: 241, Loss: 2.024200, Train accuracy: 0.543000, val accuracy: 0.546000\n",
      "Epoch: 242, Loss: 1.665558, Train accuracy: 0.542556, val accuracy: 0.546000\n",
      "Epoch: 243, Loss: 1.633311, Train accuracy: 0.543778, val accuracy: 0.545000\n",
      "Epoch: 244, Loss: 1.763883, Train accuracy: 0.543556, val accuracy: 0.546000\n",
      "Epoch: 245, Loss: 1.839842, Train accuracy: 0.544111, val accuracy: 0.546000\n",
      "Epoch: 246, Loss: 1.694042, Train accuracy: 0.544667, val accuracy: 0.546000\n",
      "Epoch: 247, Loss: 1.933601, Train accuracy: 0.544222, val accuracy: 0.546000\n",
      "Epoch: 248, Loss: 1.670932, Train accuracy: 0.545000, val accuracy: 0.546000\n",
      "Epoch: 249, Loss: 1.904381, Train accuracy: 0.545444, val accuracy: 0.546000\n",
      "Epoch: 250, Loss: 1.831760, Train accuracy: 0.545444, val accuracy: 0.546000\n",
      "Epoch: 251, Loss: 1.616500, Train accuracy: 0.546000, val accuracy: 0.546000\n",
      "Epoch: 252, Loss: 1.681760, Train accuracy: 0.545889, val accuracy: 0.546000\n",
      "Epoch: 253, Loss: 1.724707, Train accuracy: 0.545778, val accuracy: 0.546000\n",
      "Epoch: 254, Loss: 1.764320, Train accuracy: 0.546111, val accuracy: 0.546000\n",
      "Epoch: 255, Loss: 1.651806, Train accuracy: 0.546556, val accuracy: 0.546000\n",
      "Epoch: 256, Loss: 1.982237, Train accuracy: 0.546222, val accuracy: 0.546000\n",
      "Epoch: 257, Loss: 1.697304, Train accuracy: 0.546778, val accuracy: 0.548000\n",
      "Epoch: 258, Loss: 1.699881, Train accuracy: 0.546667, val accuracy: 0.549000\n",
      "Epoch: 259, Loss: 1.757679, Train accuracy: 0.546556, val accuracy: 0.548000\n",
      "Epoch: 260, Loss: 1.817790, Train accuracy: 0.547667, val accuracy: 0.549000\n",
      "Epoch: 261, Loss: 1.867832, Train accuracy: 0.547556, val accuracy: 0.550000\n",
      "Epoch: 262, Loss: 1.909242, Train accuracy: 0.548222, val accuracy: 0.549000\n",
      "Epoch: 263, Loss: 1.777007, Train accuracy: 0.549333, val accuracy: 0.551000\n",
      "Epoch: 264, Loss: 1.532140, Train accuracy: 0.549667, val accuracy: 0.550000\n",
      "Epoch: 265, Loss: 1.722648, Train accuracy: 0.549333, val accuracy: 0.551000\n",
      "Epoch: 266, Loss: 2.000252, Train accuracy: 0.549889, val accuracy: 0.550000\n",
      "Epoch: 267, Loss: 1.734076, Train accuracy: 0.550000, val accuracy: 0.552000\n",
      "Epoch: 268, Loss: 1.727408, Train accuracy: 0.549778, val accuracy: 0.552000\n",
      "Epoch: 269, Loss: 1.628964, Train accuracy: 0.550000, val accuracy: 0.551000\n",
      "Epoch: 270, Loss: 1.787304, Train accuracy: 0.550444, val accuracy: 0.552000\n",
      "Epoch: 271, Loss: 1.723328, Train accuracy: 0.550778, val accuracy: 0.552000\n",
      "Epoch: 272, Loss: 1.811643, Train accuracy: 0.550444, val accuracy: 0.553000\n",
      "Epoch: 273, Loss: 1.623408, Train accuracy: 0.550889, val accuracy: 0.553000\n",
      "Epoch: 274, Loss: 1.775409, Train accuracy: 0.551444, val accuracy: 0.553000\n",
      "Epoch: 275, Loss: 1.675778, Train accuracy: 0.551000, val accuracy: 0.554000\n",
      "Epoch: 276, Loss: 1.901070, Train accuracy: 0.551556, val accuracy: 0.553000\n",
      "Epoch: 277, Loss: 1.846359, Train accuracy: 0.551889, val accuracy: 0.553000\n",
      "Epoch: 278, Loss: 1.507020, Train accuracy: 0.552444, val accuracy: 0.553000\n",
      "Epoch: 279, Loss: 1.774278, Train accuracy: 0.552333, val accuracy: 0.554000\n",
      "Epoch: 280, Loss: 1.941172, Train accuracy: 0.552222, val accuracy: 0.554000\n",
      "Epoch: 281, Loss: 1.857605, Train accuracy: 0.552778, val accuracy: 0.553000\n",
      "Epoch: 282, Loss: 1.584959, Train accuracy: 0.552889, val accuracy: 0.553000\n",
      "Epoch: 283, Loss: 1.493143, Train accuracy: 0.553111, val accuracy: 0.554000\n",
      "Epoch: 284, Loss: 1.970499, Train accuracy: 0.553778, val accuracy: 0.554000\n",
      "Epoch: 285, Loss: 1.682050, Train accuracy: 0.553444, val accuracy: 0.554000\n",
      "Epoch: 286, Loss: 1.674654, Train accuracy: 0.554000, val accuracy: 0.554000\n",
      "Epoch: 287, Loss: 1.809425, Train accuracy: 0.553889, val accuracy: 0.553000\n",
      "Epoch: 288, Loss: 1.675031, Train accuracy: 0.554444, val accuracy: 0.554000\n",
      "Epoch: 289, Loss: 2.022093, Train accuracy: 0.554333, val accuracy: 0.555000\n",
      "Epoch: 290, Loss: 1.846617, Train accuracy: 0.555000, val accuracy: 0.554000\n",
      "Epoch: 291, Loss: 1.622896, Train accuracy: 0.555444, val accuracy: 0.554000\n",
      "Epoch: 292, Loss: 1.740878, Train accuracy: 0.555222, val accuracy: 0.556000\n",
      "Epoch: 293, Loss: 2.078383, Train accuracy: 0.555444, val accuracy: 0.554000\n",
      "Epoch: 294, Loss: 1.762673, Train accuracy: 0.555778, val accuracy: 0.555000\n",
      "Epoch: 295, Loss: 1.981018, Train accuracy: 0.555667, val accuracy: 0.555000\n",
      "Epoch: 296, Loss: 1.564302, Train accuracy: 0.555667, val accuracy: 0.555000\n",
      "Epoch: 297, Loss: 1.838546, Train accuracy: 0.556111, val accuracy: 0.555000\n",
      "Epoch: 298, Loss: 1.833966, Train accuracy: 0.556111, val accuracy: 0.559000\n",
      "Epoch: 299, Loss: 1.812952, Train accuracy: 0.556444, val accuracy: 0.559000\n",
      "Epoch: 300, Loss: 1.963442, Train accuracy: 0.556444, val accuracy: 0.559000\n",
      "Epoch: 301, Loss: 1.871976, Train accuracy: 0.556333, val accuracy: 0.559000\n",
      "Epoch: 302, Loss: 1.907471, Train accuracy: 0.556778, val accuracy: 0.559000\n",
      "Epoch: 303, Loss: 1.807126, Train accuracy: 0.556889, val accuracy: 0.559000\n",
      "Epoch: 304, Loss: 1.647021, Train accuracy: 0.557333, val accuracy: 0.559000\n",
      "Epoch: 305, Loss: 1.866212, Train accuracy: 0.556889, val accuracy: 0.559000\n",
      "Epoch: 306, Loss: 1.849315, Train accuracy: 0.558000, val accuracy: 0.559000\n",
      "Epoch: 307, Loss: 1.684534, Train accuracy: 0.558222, val accuracy: 0.559000\n",
      "Epoch: 308, Loss: 1.825908, Train accuracy: 0.559111, val accuracy: 0.559000\n",
      "Epoch: 309, Loss: 1.741757, Train accuracy: 0.559000, val accuracy: 0.559000\n",
      "Epoch: 310, Loss: 1.725344, Train accuracy: 0.559222, val accuracy: 0.559000\n",
      "Epoch: 311, Loss: 1.618885, Train accuracy: 0.559222, val accuracy: 0.559000\n",
      "Epoch: 312, Loss: 1.858137, Train accuracy: 0.559333, val accuracy: 0.560000\n",
      "Epoch: 313, Loss: 1.747939, Train accuracy: 0.559667, val accuracy: 0.559000\n",
      "Epoch: 314, Loss: 1.853660, Train accuracy: 0.559222, val accuracy: 0.560000\n",
      "Epoch: 315, Loss: 1.749154, Train accuracy: 0.559222, val accuracy: 0.559000\n",
      "Epoch: 316, Loss: 1.730680, Train accuracy: 0.559444, val accuracy: 0.559000\n",
      "Epoch: 317, Loss: 1.905146, Train accuracy: 0.559889, val accuracy: 0.560000\n",
      "Epoch: 318, Loss: 2.009239, Train accuracy: 0.559889, val accuracy: 0.561000\n",
      "Epoch: 319, Loss: 2.013865, Train accuracy: 0.560111, val accuracy: 0.560000\n",
      "Epoch: 320, Loss: 1.537354, Train accuracy: 0.559889, val accuracy: 0.561000\n",
      "Epoch: 321, Loss: 1.597018, Train accuracy: 0.560333, val accuracy: 0.561000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 322, Loss: 1.754462, Train accuracy: 0.560778, val accuracy: 0.561000\n",
      "Epoch: 323, Loss: 1.947542, Train accuracy: 0.560778, val accuracy: 0.560000\n",
      "Epoch: 324, Loss: 1.924437, Train accuracy: 0.560444, val accuracy: 0.561000\n",
      "Epoch: 325, Loss: 1.715731, Train accuracy: 0.560667, val accuracy: 0.561000\n",
      "Epoch: 326, Loss: 1.812885, Train accuracy: 0.561222, val accuracy: 0.561000\n",
      "Epoch: 327, Loss: 1.625511, Train accuracy: 0.561222, val accuracy: 0.561000\n",
      "Epoch: 328, Loss: 1.912723, Train accuracy: 0.561333, val accuracy: 0.561000\n",
      "Epoch: 329, Loss: 1.662766, Train accuracy: 0.561556, val accuracy: 0.561000\n",
      "Epoch: 330, Loss: 1.616348, Train accuracy: 0.561556, val accuracy: 0.561000\n",
      "Epoch: 331, Loss: 1.473631, Train accuracy: 0.561333, val accuracy: 0.561000\n",
      "Epoch: 332, Loss: 1.575134, Train accuracy: 0.561556, val accuracy: 0.561000\n",
      "Epoch: 333, Loss: 1.699645, Train accuracy: 0.561444, val accuracy: 0.561000\n",
      "Epoch: 334, Loss: 2.076673, Train accuracy: 0.561333, val accuracy: 0.561000\n",
      "Epoch: 335, Loss: 1.904961, Train accuracy: 0.561889, val accuracy: 0.561000\n",
      "Epoch: 336, Loss: 1.922329, Train accuracy: 0.561778, val accuracy: 0.561000\n",
      "Epoch: 337, Loss: 1.763331, Train accuracy: 0.561667, val accuracy: 0.561000\n",
      "Epoch: 338, Loss: 1.676239, Train accuracy: 0.562000, val accuracy: 0.561000\n",
      "Epoch: 339, Loss: 1.872414, Train accuracy: 0.561889, val accuracy: 0.561000\n",
      "Epoch: 340, Loss: 1.698313, Train accuracy: 0.562444, val accuracy: 0.561000\n",
      "Epoch: 341, Loss: 1.813467, Train accuracy: 0.562222, val accuracy: 0.561000\n",
      "Epoch: 342, Loss: 1.755964, Train accuracy: 0.562222, val accuracy: 0.562000\n",
      "Epoch: 343, Loss: 1.825423, Train accuracy: 0.562000, val accuracy: 0.562000\n",
      "Epoch: 344, Loss: 2.032521, Train accuracy: 0.562111, val accuracy: 0.562000\n",
      "Epoch: 345, Loss: 1.563787, Train accuracy: 0.562111, val accuracy: 0.561000\n",
      "Epoch: 346, Loss: 1.732264, Train accuracy: 0.562111, val accuracy: 0.562000\n",
      "Epoch: 347, Loss: 1.916641, Train accuracy: 0.562778, val accuracy: 0.562000\n",
      "Epoch: 348, Loss: 1.740768, Train accuracy: 0.562667, val accuracy: 0.561000\n",
      "Epoch: 349, Loss: 1.614567, Train accuracy: 0.562444, val accuracy: 0.561000\n",
      "best validation accuracy achieved: 0.562000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-3\n",
    "reg_strength = 1e-2\n",
    "learning_rate_decay = 0.99\n",
    "hidden_layer_size = 1024\n",
    "num_epochs = 350\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_size, reg = reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=learning_rates, num_epochs=num_epochs, batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "best_val_accuracy = max(val_history)\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1150127c0>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.514000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
